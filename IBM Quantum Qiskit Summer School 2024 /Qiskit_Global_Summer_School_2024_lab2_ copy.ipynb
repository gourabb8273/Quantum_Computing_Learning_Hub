{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3bxNy98wlQQ"
      },
      "source": [
        "# Lab 2: Utility-Scale Layer Fidelity Experiment\n",
        "\n",
        "Samantha Barron, Haimeng Zhang"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q qiskit[visualization]==1.1.0\n",
        "# Use the following if you are on MacOS/zsh\n",
        "#!pip install 'qiskit[visualization]'==1.1.0\n",
        "!pip -q install qiskit_aer\n",
        "!pip -q install qiskit_ibm_runtime\n",
        "!pip -q install matplotlib\n",
        "!pip -q install pylatexenc\n",
        "!pip -q install prototype-zne\n",
        "!pip -q install git+https://github.com/qiskit-community/Quantum-Challenge-Grader.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzxS0kyTwyV5",
        "outputId": "51a6bac2-533f-4c7b-b644-643430959531"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ibm-platform-services (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ibm-cloud-sdk-core (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for qc-grader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9AVeangwlQT"
      },
      "source": [
        "In this lab we will show a guided construction of how to calculate the EPLG (Error Per Layered Gate) and LF (Layer Fidelity). These metrics quantify error rates in a circuit, and are particularly useful in understanding the overhead required to run error mitigation at utility-scale workloads.\n",
        "\n",
        "For more details on the background of these metrics, see the [Quantum Research Blog post](https://www.ibm.com/quantum/blog/quantum-metric-layer-fidelity) or the associated technical paper, [Benchmarking Quantum Processor Performance at Scale](https://arxiv.org/abs/2311.05933). You can also find an implementation of the Layer Fidelity experiment [here](https://github.com/qiskit-community/qiskit-device-benchmarking/blob/main/notebooks/layer_fidelity.ipynb) using `qiskit-experiments` module, whereas, in this notebook, we will directly use Qiskit Runtime Primitives for circuit execution.\n",
        "\n",
        "The first few parts of this lab contain graded exercises, whereas the latter portions of this lab are a guided walkthrough of how to use the Qiskit Runtime to do these utility-scale calculations.\n",
        "\n",
        "Table of Contents:\n",
        "- In Section 0 we list the package requirement to run this notebook.\n",
        "- In Sections 1-3 we will set up the layers and associated circuits which define the disjoint sets of qubits on which we will perform EPLG calculations.\n",
        "- In Section 4 we construct the total EPLG circuits.\n",
        "- In Section 5-7 we construct the `BindingsArray`, `ObservablesArray`s, and `EstimatorPub`s for the EPLG characterization.\n",
        "- In Section 8 we submit these to the `EstimatorV2` Qiskit Runtime Primitive.\n",
        "- In Section 9 we perform the data analysis and fittings used to extract the EPLG and LF with the resulting data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHLIz6UiwlQU"
      },
      "source": [
        "# Part 0: Requirements\n",
        "\n",
        "To run this notebook, you will need to install the following packages:\n",
        "\n",
        "For circuit construction and execution on the IBM Quantum hardware:\n",
        "```\n",
        "qiskit >= 1.0.0\n",
        "qiskit-ibm-runtime >= 0.21.1\n",
        "```\n",
        "For data analysis and display:\n",
        "```\n",
        "lmfit\n",
        "pandas\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVxt3AzawlQU",
        "outputId": "f2d84fb1-fb43-41eb-e771-4120e52bb558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: QXToken=16d6dd47657b972c1547b10fb7844fd1a407cc047430da104bd28a29a7394da2ea55115ecfcd09ba4e930ff8372156429ecf693000068b161a776b05b93c191b\n"
          ]
        }
      ],
      "source": [
        "### Save API Token, if needed\n",
        "%set_env QXToken=16d6dd47657b972c1547b10fb7844fd1a407cc047430da104bd28a29a7394da2ea55115ecfcd09ba4e930ff8372156429ecf693000068b161a776b05b93c191b\n",
        "\n",
        "# Make sure there is no space between the equal sign\n",
        "# and the beginning of your token\n",
        "# Make sure you do NOT ADD QUOTATION MARKS!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p2gkwXUwlQV"
      },
      "source": [
        "# Part 1: Define 1-D Chain\n",
        "To start, we will choose a backend. In this lab you can choose whatever backend you want.\n",
        "\n",
        "In order to compute the EPLG and LF, we need to choose a chain of qubits on the device to characterize. The first problem is this, you should provide:\n",
        "1. A chain of qubits on the device which is a simply connected path graph of qubits on the device. I.e., provide a list `PATH_ANSWER: list[int]` whose elements are physical qubits on the device, and adjacent elements of the list are connected on the coupling map by edges. The list should contain at least `3` elements.\n",
        "2. The backend you have chosen: `BACKEND: IBMBackend`.\n",
        "\n",
        "Answers to grade:\n",
        "- `PATH_ANSWER: list[int]`\n",
        "- `BACKEND: IBMBackend`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JeeGokHNwlQW"
      },
      "outputs": [],
      "source": [
        "from qiskit_ibm_runtime import QiskitRuntimeService\n",
        "\n",
        "from qiskit.providers.fake_provider import GenericBackendV2, generic_backend_v2\n",
        "# # Choose a real backend\n",
        "QiskitRuntimeService.save_account(\n",
        "    channel=\"ibm_quantum\",\n",
        "    token=\"16d6dd47657b972c1547b10fb7844fd1a407cc047430da104bd28a29a7394da2ea55115ecfcd09ba4e930ff8372156429ecf693000068b161a776b05b93c191b\",\n",
        "    set_as_default=True,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "# # Load saved credentials\n",
        "# service = QiskitRuntimeService()\n",
        "service = QiskitRuntimeService()\n",
        "backend = service.backend(\"ibm_osaka\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IYnsdU7pwlQW"
      },
      "outputs": [],
      "source": [
        "# part 1: pick a backend and define 1-D chain\n",
        "\n",
        "### Your code goes here ###\n",
        "\n",
        "BACKEND = backend\n",
        "\n",
        "PATH_ANSWER =  backend.configuration().coupling_map[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk8igBg8wlQW",
        "outputId": "84a04c1b-4113-4e24-984b-41a45291286d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting your answer. Please wait...\n",
            "Nice work, all your answers look correct!\n"
          ]
        }
      ],
      "source": [
        "# grade part 1\n",
        "from qc_grader.challenges.qgss_2024 import grade_lab2_ex1\n",
        "grade_lab2_ex1(PATH_ANSWER, BACKEND)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PATH_ANSWER, BACKEND)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoQhIAESy5tw",
        "outputId": "b17b53b9-a75a-4eed-d5df-a44839909f1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0] <IBMBackend('ibm_osaka')>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLig3es4wlQX"
      },
      "source": [
        "# Part 2: Define Disjoint Layers\n",
        "\n",
        "Next, we need to form two sets of edges which correspond to the different layers we will use in benchmarking, say `LAYER_1_ANSWER` and `LAYER_2_ANSWER`, each with type `list[tuple[int, int]]`. These layers should have the following properties:\n",
        "- Each `LAYER_i_ANSWER` contains edges on distinct sets of qubits, e.g. `(0, 1)` and `(1, 2)` cannot both be in `LAYER_i_ANSWER`, since they both contain `1`.\n",
        "- Every qubit in `PATH_ANSWER` must be contained in at least one of the `LAYER_i`s.\n",
        "\n",
        "Answers to grade:\n",
        "- `LAYER_1_ANSWER: list[tuple[int, int]]`\n",
        "- `LAYER_2_ANSWER: list[tuple[int, int]]`\n",
        "- `PATH_ANSWER: list[int]` (same as before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfqx6sscwlQX"
      },
      "outputs": [],
      "source": [
        "# part 2: define disjoint layers from a 1D chain\n",
        "\n",
        "### Your code goes here ###\n",
        "\n",
        "# LAYER_1_ANSWER =\n",
        "# LAYER_2_ANSWER ="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LAYER_1_ANSWER = []\n",
        "LAYER_2_ANSWER = []\n",
        "\n",
        "# Iterate through the path and create two disjoint sets of edges\n",
        "for i in range(len(PATH_ANSWER) - 1):\n",
        "    if i % 2 == 0:\n",
        "        LAYER_1_ANSWER.append((PATH_ANSWER[i], PATH_ANSWER[i + 1]))\n",
        "    else:\n",
        "        LAYER_2_ANSWER.append((PATH_ANSWER[i], PATH_ANSWER[i + 1]))\n",
        "\n",
        "# Output the results\n",
        "print(\"PATH_ANSWER:\", PATH_ANSWER)\n",
        "print(\"LAYER_1_ANSWER:\", LAYER_1_ANSWER)\n",
        "print(\"LAYER_2_ANSWER:\", LAYER_2_ANSWER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeXqvSu4zK7e",
        "outputId": "5393a7ef-34d0-4a20-e79e-211f9f895980"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PATH_ANSWER: [1, 0]\n",
            "LAYER_1_ANSWER: [(1, 0)]\n",
            "LAYER_2_ANSWER: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4z4xE0UwlQY",
        "outputId": "f87f49f8-a8f4-4fce-fb1b-8052b18d1a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting your answer. Please wait...\n",
            "Nice work, all your answers look correct!\n"
          ]
        }
      ],
      "source": [
        "# grade part 2\n",
        "from qc_grader.challenges.qgss_2024 import grade_lab2_ex2\n",
        "grade_lab2_ex2(LAYER_1_ANSWER, LAYER_2_ANSWER, PATH_ANSWER, BACKEND)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6h-Zs-YwlQY"
      },
      "source": [
        "# Part 3: Construct Clifford Entangling Layers\n",
        "Now we can use the `LAYER_i` from the previous problem to construct the `QuantumCircuit`s for each layer, which we will use for the EPLG experiments. Now it's your job to construct two circuits, `CIRC_1_ANSWER` and `CIRC_2_ANSWER`.\n",
        "- Each of them should contain a two-qubit Clifford gate for every pair in `LAYER_1_ANSWER` and `LAYER_2_ANSWER` from before.\n",
        "- The two-qubit Clifford gate (`GATE_NAME`) must be one provided by the backend you choose, i.e. it is in `backend.basis_gates`, should be one of `'ecr'`, `'cz'` or `'cx'` depending on your backend.\n",
        "\n",
        "Answers to grade:\n",
        "- `CIRCUIT_1_ANSWER: QuantumCircuit`\n",
        "- `CIRCUIT_2_ANSWER: QuantumCircuit`\n",
        "- `LAYER_1_ANSWER: list[tuple[int, int]]` (same as before)\n",
        "- `LAYER_2_ANSWER: list[tuple[int, int]]` (same as before)\n",
        "- `GATE_NAME: str`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J75LwdthwlQY"
      },
      "outputs": [],
      "source": [
        "# part 2: define disjoint layers from a 1D chain\n",
        "\n",
        "### Your code goes here ###\n",
        "\n",
        "# CIRC_1_ANSWER =\n",
        "# CIRC_2_ANSWER ="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "\n",
        "# Define gate name (choose from 'cz', 'ecr', 'cx' based on your backend)\n",
        "GATE_NAME = 'cz'\n",
        "\n",
        "# Initialize QuantumCircuit objects\n",
        "CIRC_1_ANSWER = QuantumCircuit(len(PATH_ANSWER))\n",
        "CIRC_2_ANSWER = QuantumCircuit(len(PATH_ANSWER))\n",
        "\n",
        "# Add gates based on LAYER_1_ANSWER\n",
        "for q1, q2 in LAYER_1_ANSWER:\n",
        "    print(q1,q2)\n",
        "    if GATE_NAME == 'cz':\n",
        "        CIRC_1_ANSWER.cz(q1, q2)\n",
        "    elif GATE_NAME == 'ecr':\n",
        "        # Replace with appropriate gate for 'ecr'\n",
        "        CIRC_1_ANSWER.ecr(q1, q2)\n",
        "    elif GATE_NAME == 'cx':\n",
        "        CIRC_1_ANSWER.cx(q1, q2)\n",
        "\n",
        "# Add gates based on LAYER_2_ANSWER\n",
        "for q1, q2 in LAYER_2_ANSWER:\n",
        "    print(q1,q2)\n",
        "    if GATE_NAME == 'cz':\n",
        "        CIRC_2_ANSWER.cz(q1, q2)\n",
        "    elif GATE_NAME == 'ecr':\n",
        "        # Replace with appropriate gate for 'ecr'\n",
        "        CIRC_2_ANSWER.ecr(q1, q2)\n",
        "    elif GATE_NAME == 'cx':\n",
        "        CIRC_2_ANSWER.cx(q1, q2)\n",
        "\n",
        "# Print the circuits for verification\n",
        "print(\"CIRC_1_ANSWER:\")\n",
        "print(CIRC_1_ANSWER)\n",
        "print(\"\\nCIRC_2_ANSWER:\")\n",
        "print(CIRC_2_ANSWER)\n",
        "print(\"\\nLAYER_1_ANSWER:\", LAYER_1_ANSWER)\n",
        "print(\"LAYER_2_ANSWER:\", LAYER_2_ANSWER)\n",
        "print(\"GATE_NAME:\", GATE_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojsUkaCRzfV_",
        "outputId": "64911880-b028-46ee-84b1-2ed2f4cfadbc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0\n",
            "CIRC_1_ANSWER:\n",
            "        \n",
            "q_0: ─■─\n",
            "      │ \n",
            "q_1: ─■─\n",
            "        \n",
            "\n",
            "CIRC_2_ANSWER:\n",
            "     \n",
            "q_0: \n",
            "     \n",
            "q_1: \n",
            "     \n",
            "\n",
            "LAYER_1_ANSWER: [(1, 0)]\n",
            "LAYER_2_ANSWER: []\n",
            "GATE_NAME: cz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B34VHVWwlQY",
        "outputId": "c03662ac-805c-4d6d-ecb2-1f1362eb55a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting your answer. Please wait...\n",
            "Nice work, all your answers look correct!\n",
            "Submitting your answer. Please wait...\n",
            "Nice work, all your answers look correct!\n"
          ]
        }
      ],
      "source": [
        "# grade part 3\n",
        "from qc_grader.challenges.qgss_2024 import grade_lab2_ex3\n",
        "grade_lab2_ex3(CIRC_1_ANSWER, LAYER_1_ANSWER, GATE_NAME, BACKEND)\n",
        "grade_lab2_ex3(CIRC_2_ANSWER, LAYER_2_ANSWER, GATE_NAME, BACKEND)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcYcWMZwwlQY"
      },
      "source": [
        "# Part 4: Construct EPLG Experiment Circuits\n",
        "\n",
        "*No grading for this part*\n",
        "\n",
        "In this part, we will use the circuits you constructed to construct the total EPLG circuits.  These circuits interleave the layers from before between layers of random Clifford gates.\n",
        "\n",
        "A few technical asides:\n",
        "1. There is a slight difference between the circuits constructed here and those defined in the EPLG paper. For a circuit of depth $d$ (for even $d$), we randomly sample 1q Clifford gates for $d/2$ layers, and then we invert the circuit for the last $d/2$ layers. This provides a simple implmentation for our purposes, and the details of this difference are beyond the scope of this lab.\n",
        "2. We perform 1q Clifford sampling by taking advantage of the fact that for backends whose single qubit gates are composed of $R_z(\\theta_1) \\sqrt{X} R_z(\\theta_2) \\sqrt{X} R_z(\\theta_3)$, when $\\theta_i \\in \\{ \\pm \\pi / 2, \\pm \\pi, 0 \\}$, the resulting single qubit gate is a Clifford. This allows us to randomly sample 1q Clifford gates simply by changing parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gPItc-P9wlQZ"
      },
      "outputs": [],
      "source": [
        "from qiskit.circuit import Parameter\n",
        "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
        "\n",
        "def eplg_circuit(num_qubits: int, depth: int, layer: QuantumCircuit, qubits: tuple[int, ...]) -> QuantumCircuit:\n",
        "    if depth % 2 != 0:\n",
        "        raise ValueError(f\"The depth must be even, got {depth}\")\n",
        "\n",
        "    def parameters():\n",
        "        _depth = 0\n",
        "        while True:\n",
        "            for zi in range(3):\n",
        "                for q in range(num_qubits):\n",
        "                    yield Parameter(f\"d{_depth}_q{q}_z{zi}\")\n",
        "            _depth += 1\n",
        "    _parameters = parameters()\n",
        "\n",
        "    circ = QuantumCircuit(num_qubits)\n",
        "\n",
        "    def _1q_layer():\n",
        "        for j in range(3):\n",
        "            for k in qubits:\n",
        "                circ.rz(next(_parameters), k)\n",
        "            if j == 2:\n",
        "                continue\n",
        "            circ.sx(qubits)\n",
        "\n",
        "    for _depth in range(depth // 2):\n",
        "        circ.barrier(qubits)\n",
        "        _1q_layer()\n",
        "        circ.barrier(qubits)\n",
        "        circ.compose(layer, inplace=True)\n",
        "    circ.barrier(qubits)\n",
        "    _1q_layer()\n",
        "    circ.barrier(qubits)\n",
        "\n",
        "    # Assuming mirroring is fine\n",
        "    circ = circ.compose(circ.inverse())\n",
        "\n",
        "    circ.measure_active()\n",
        "\n",
        "    pm = generate_preset_pass_manager(basis_gates=[\"ecr\", \"sx\", \"rz\"], optimization_level=0)\n",
        "    circ = pm.run(circ)\n",
        "\n",
        "    circ.metadata[\"layer_depth\"] = depth\n",
        "    circ.metadata[\"qubits\"] = qubits\n",
        "    circ.metadata[\"num_qubits\"] = num_qubits\n",
        "\n",
        "    return circ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dZmVu-gwlQZ"
      },
      "source": [
        "Here are examples of the EPLG circuits for depth $d=4$. In a later part we will use this function to construct circuits for varying $d$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sK2AbfnlwlQZ"
      },
      "outputs": [],
      "source": [
        "example_circuit_1 = eplg_circuit(\n",
        "    num_qubits=BACKEND.num_qubits,\n",
        "    depth=4,\n",
        "    layer=CIRC_1_ANSWER,\n",
        "    qubits=PATH_ANSWER,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fzhLyeN8wlQZ"
      },
      "outputs": [],
      "source": [
        "example_circuit_2 = eplg_circuit(\n",
        "    num_qubits=BACKEND.num_qubits,\n",
        "    depth=4,\n",
        "    layer=CIRC_2_ANSWER,\n",
        "    qubits=PATH_ANSWER,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ggB88rwlQZ"
      },
      "source": [
        "# Part 5: Construct `BindingsArray`s\n",
        "\n",
        "*No grading for this part*\n",
        "\n",
        "In the previous section, the circuits we constructed are parameterized such that if we sample with the appropriate values, they will always produce random single-qubit Clifford gates.\n",
        "\n",
        "For our EPLG calculations, we need to sample lots of sets of parameters. This is expressed conveniently with the `BindingsArray`. The `BindingsArray` can be thought of as an array whose elements correspond to sets of parameters and their bound values.\n",
        "\n",
        "For example, if we have a circuit with $k$ parameters, and we need to sample all of the parameters $m$ times, the `BindingsArray` that accomplishes this would have shape `(m,)`. Similarly, if we want to have a more complicated set of bindings to perform, our `BindingsArray` can have arbitrary shape, and supports `numpy`-like reshaping operations, slicing, etc.\n",
        "\n",
        "In this section, we will construct a function which accepts a `QuantumCircuit`, the number of samples we want to perform, and a `numpy` RNG to perform the single-qubit Clifford sampling. We will use this later on to produce our `EstimatorPub`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bttTLDpqwlQZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from qiskit.primitives.containers.bindings_array import BindingsArray\n",
        "\n",
        "def get_clifford_rz_samples(\n",
        "    circ: QuantumCircuit,\n",
        "    num_samples: int,\n",
        "    rng: np.random.Generator,\n",
        ") -> BindingsArray:\n",
        "    \"\"\"Uniformly sample the Rz parameters in a `QuantumCircuit`\n",
        "    from -pi, -pi/2, 0, +pi/2, +pi.\n",
        "    \"\"\"\n",
        "\n",
        "    _allowed_ops = {'rz', 'sx', 'sxdg', 'ecr', 'barrier', 'measure'}\n",
        "    if (_other := set(circ.count_ops().keys()) - _allowed_ops):\n",
        "        raise ValueError(f\"Circuit must only contain ops: {_allowed_ops}, got {_other}\")\n",
        "\n",
        "    sampled_pars = rng.integers(-2, 3, size=(num_samples, len(circ.parameters))) * (np.pi/2)\n",
        "\n",
        "    return BindingsArray({\n",
        "        tuple(circ.parameters): sampled_pars\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKkX9OxnwlQa"
      },
      "source": [
        "As an example, we can take each of our circuits and produce bindings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JwhBldWhwlQa"
      },
      "outputs": [],
      "source": [
        "num_samples = 10\n",
        "ARRAY_1_ANSWER = get_clifford_rz_samples(\n",
        "    circ=example_circuit_1,\n",
        "    num_samples=num_samples,\n",
        "    rng=np.random.default_rng(42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoSxA4KXwlQa",
        "outputId": "5d77baec-58e2-4479-b3ea-03e823934798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting your answer. Please wait...\n",
            "Nice work, all your answers look correct! \n",
            " Notice that the shape of the BindingsArray is [10], and there are {num_parameters} parameters.\n"
          ]
        }
      ],
      "source": [
        "# grade part 4\n",
        "from qc_grader.challenges.qgss_2024 import grade_lab2_ex4\n",
        "grade_lab2_ex4(ARRAY_1_ANSWER, example_circuit_1, num_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKF5DK88wlQa"
      },
      "source": [
        "Notice that despite the large number of parameters, the `BindingsArray` has shape `(10,)`, meaning it has `10` entries. As we discussed before, this is because its elements correspond to sets of parameters and their bound values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgMlqowlQa"
      },
      "source": [
        "# Part 6: Make `ObservablesArray`s\n",
        "\n",
        "*No grading for this part*\n",
        "\n",
        "The only remaining thing that we need to produce an `EstimatorPub` is an `ObservablesArray`. The `ObservablesArray` can be seen as a array whose elements are observables. In our case, they will be `SparsePauliOp`s.\n",
        "\n",
        "In order to calculate the EPLG and LF, we need to calculate the expectation values $\\text{Tr}\\left( \\rho \\ket{00}_{i,j}\\bra{00}_{i,j}\\right)$ and $\\text{Tr}\\left( \\rho \\ket{0}_{i}\\bra{0}_{i}\\right)$ for qubits $i$, $j$ depending on the layers we chose before.\n",
        "\n",
        "Alternatively we could do this using the `SamplerV2` rather than the `EstimatorV2`. This would come with the tradeoff of having more post-processing that we have to do, but we can have the `EstimatorV2` do this for us by constructing the projectors $\\ket{0}_{i}\\bra{0}_{i}$ and $\\ket{00}_{i,j}\\bra{00}_{i,j}$ and using them as observables.\n",
        "\n",
        "This means that the expectation values we get back from the `EstimatorV2` will be the process fidelities that we're interested in!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93d30VIVwlQa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "\n",
        "def process_fidelity_observable(num_qubits: int, qubits: tuple[int, ...]) -> SparsePauliOp:\n",
        "    \"\"\"Produces the all 0 projector on `qubits` tensored with the identity on all other qubits\"\"\"\n",
        "    pauli_strings = []\n",
        "\n",
        "    for p_sub_str in product([\"I\", \"Z\"], repeat=len(qubits)):\n",
        "        p_str = [\"I\"] * num_qubits\n",
        "        for qi, pi in zip(qubits, p_sub_str):\n",
        "            p_str[qi] = pi\n",
        "        pauli_strings.append(\"\".join(p_str[::-1]))\n",
        "\n",
        "    return SparsePauliOp(pauli_strings, np.ones(len(pauli_strings)) / 2**len(qubits))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0dcQTWdwlQa"
      },
      "source": [
        "Now we need to produce `ObservablesArray`s which correspond to the projectors we are interested in, i.e. the process fidelities for subsets of our path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m82CKvQXwlQa"
      },
      "outputs": [],
      "source": [
        "from qiskit.primitives.containers.observables_array import ObservablesArray\n",
        "\n",
        "LAYER_1_SUBSYSTEMS = LAYER_1_ANSWER + [(q,) for q in set(PATH_ANSWER) - set(item for sublist in LAYER_1_ANSWER for item in sublist)]\n",
        "LAYER_2_SUBSYSTEMS = LAYER_2_ANSWER + [(q,) for q in set(PATH_ANSWER) - set(item for sublist in LAYER_2_ANSWER for item in sublist)]\n",
        "\n",
        "LAYER_1_OBSERVABLES = ObservablesArray([process_fidelity_observable(BACKEND.num_qubits, qubits) for qubits in LAYER_1_SUBSYSTEMS])\n",
        "LAYER_2_OBSERVABLES = ObservablesArray([process_fidelity_observable(BACKEND.num_qubits, qubits) for qubits in LAYER_2_SUBSYSTEMS])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOm2p_IkwlQa"
      },
      "source": [
        "Note that the `LAYER_i_OBSERVABLES` have a shape which corresponds to the number of subsystems in each layer.\n",
        "\n",
        "Since all of the observables in our `ObservablesArray`s are diagonal in the computational basis (i.e. they only consist of Paulis which have $I$ and $Z$ terms), the `EstimatorV2` does not need to compute expectation values in additional bases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH6tDdUDwlQa"
      },
      "outputs": [],
      "source": [
        "LAYER_1_OBSERVABLES.shape == (len(LAYER_1_SUBSYSTEMS),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6X8DrjwwlQa"
      },
      "outputs": [],
      "source": [
        "LAYER_2_OBSERVABLES.shape == (len(LAYER_2_SUBSYSTEMS),)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba_eSyTBwlQb"
      },
      "source": [
        "# Part 7: Make Sequence of `EstimatorPub`s\n",
        "\n",
        "*No grading for this part*\n",
        "\n",
        "Finally, we can construct our `EstimatorPub`s. The [`EstimatorPub`](https://github.com/Qiskit/qiskit/blob/main/qiskit/primitives/containers/estimator_pub.py#L36) is can be seen as a tuple consisting of a `QuantumCircuit`, an `ObservablesArray`, and a `BindingsArray` (and optionally a precision). Given an `EstimatorPub` with a given shape, the `EstimatorV2` will return arrays of expectation values (and their standard deviations) whose shape is the same as the input `EstimatorPub`.\n",
        "\n",
        "In order to construct the `EstimatorPub`s needed to do the EPLG calculations, we need `EstimatorPub`s which vary in\n",
        "- the input circuit (i.e. one for each disjoint set of edges) (in our case `2`)\n",
        "- the depth of the circuit (we have chosen `6` depths here by default).\n",
        "\n",
        "Therefore, we will have $2 \\times 6 = 12$ `EstimatorPub`s total. Within each of these, we have `10` twirling samples, and `k` fidelities (which depends on the path you chose, this should roughly be half of the length of the path). So we have $12$ `EstimatorPub`s, each with $10 k$ elements.\n",
        "\n",
        "Therefore, the total number of expectation values that we *expect* to receive is $120k$. For a length $30$ chain, $k = 15$, meaning we should roughly $1,800$ expectation values back overall (depending on the edges of the chain)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDxPdiSQwlQb"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(42)\n",
        "num_samples = 10\n",
        "depths = [2, 4, 8, 16, 32, 64]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5Zyi6WRwlQb"
      },
      "outputs": [],
      "source": [
        "from qiskit.primitives.containers.estimator_pub import EstimatorPub\n",
        "\n",
        "estimator_pubs = []\n",
        "for depth in depths:\n",
        "    for layer, name, observables in [(CIRC_1_ANSWER, \"circ_1\", LAYER_1_OBSERVABLES), (CIRC_2_ANSWER, \"circ_2\", LAYER_2_OBSERVABLES)]:\n",
        "        circ = eplg_circuit(\n",
        "            num_qubits=BACKEND.num_qubits,\n",
        "            depth=depth,\n",
        "            layer=layer,\n",
        "            qubits=PATH_ANSWER,\n",
        "        )\n",
        "        circ.metadata[\"layer_idx\"] = name\n",
        "        bindings_array = get_clifford_rz_samples(\n",
        "            circ=circ,\n",
        "            num_samples=num_samples,\n",
        "            rng=rng,\n",
        "        )\n",
        "\n",
        "        # We need to reshape the `ObservablesArray`s and `BindingsArray`s so they\n",
        "        # can be broadcasted.\n",
        "        # https://numpy.org/doc/stable/user/basics.broadcasting.html#basics-broadcasting\n",
        "        estimator_pubs.append(EstimatorPub(\n",
        "            circuit=circ,\n",
        "            observables=observables.reshape((*observables.shape, 1)),\n",
        "            parameter_values=bindings_array.reshape((1, *bindings_array.shape)),\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ZEnBfxwlQb"
      },
      "source": [
        "As a sanity check, we can count the number of expectation values we should obtain overall from the shape of the `EstimatorPub`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdvE90kXwlQb"
      },
      "outputs": [],
      "source": [
        "num_evs_expected = 0\n",
        "for pub in estimator_pubs:\n",
        "    num_evs_expected += np.prod(estimator_pubs[0].shape)\n",
        "num_evs_expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCW1cSuRwlQb"
      },
      "source": [
        "# Part 8: Submit to Runtime\n",
        "\n",
        "*No grading for this part*\n",
        "\n",
        "Finally, we are ready to hand off our `EstimatorPub`s to the `EstimatorV2`.\n",
        "\n",
        "Since the calculation of EPLG is SPAM-robust, we should turn off measurement mitigation, which is enabled by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0plQuapwlQb"
      },
      "outputs": [],
      "source": [
        "from qiskit_ibm_runtime import EstimatorV2\n",
        "estimator = EstimatorV2(backend=BACKEND)\n",
        "estimator.options.resilience.measure_mitigation = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_tJZt2dwlQh"
      },
      "source": [
        "Now we can run the `EstimatorV2` with our `EstimatorPub`s and wait for the result.\n",
        "\n",
        "With the default settings in this notebook, this should take no more than 10 minutes to complete (not accounting for queue time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVbo2-p3wlQh"
      },
      "outputs": [],
      "source": [
        "estimator_job = estimator.run(estimator_pubs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-9cSCTuwlQi"
      },
      "source": [
        "And we can get the `PrimitiveResult` with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OggDWSOcwlQi"
      },
      "outputs": [],
      "source": [
        "primitive_result = estimator_job.result()\n",
        "\n",
        "primitive_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYqpn9PwlQi"
      },
      "source": [
        "# Part 9: Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLY8Bi9kwlQi"
      },
      "source": [
        "The final step is to perform the fittings of the decay curves to perform the EPLG analysis.\n",
        "\n",
        "Let's first grab some of the relevant data from the `PrimitiveResult`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpJ4fKmiwlQi"
      },
      "outputs": [],
      "source": [
        "data_out = {\n",
        "    \"evs\": [pub_res.data.evs for pub_res in primitive_result],\n",
        "    \"stds\": [pub_res.data.stds for pub_res in primitive_result],\n",
        "    \"result_metadata\": primitive_result.metadata,\n",
        "    \"pub_metadata\": [pub_res.metadata for pub_res in primitive_result]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAIftSobwlQi"
      },
      "source": [
        "Now we can rearrange the expectation values into an array in a convenient form, as well as average over the randomized Cliffords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fly7e6hrwlQi"
      },
      "outputs": [],
      "source": [
        "# evs_at_depth is a\n",
        "evs_at_depth = np.zeros((len(depths), data_out['evs'][0].shape[0]*2))\n",
        "for i in range(len(depths)):\n",
        "    layer1_evs = np.average(data_out['evs'][2*i], axis=-1)\n",
        "    layer2_evs = np.average(data_out['evs'][2*i+1], axis=-1)\n",
        "    evs_at_depth[i,:] = np.array([item for pair in zip(layer1_evs, layer2_evs) for item in pair])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fc19PT1wlQi"
      },
      "source": [
        "The resulting shape has two axes, one for the depth (axis `0`, with shape `6`) and one for the number of subsystem fidelities (axis `1`, dependent on your path)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt_cuv7qwlQi"
      },
      "outputs": [],
      "source": [
        "evs_at_depth.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSoltBILwlQi"
      },
      "source": [
        "Now we can plot the decay curves for the different subsystems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppJ1_EKXwlQi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxEnwx3_wlQi"
      },
      "outputs": [],
      "source": [
        "ax = plt.gca()\n",
        "for i in range(evs_at_depth.shape[1]):\n",
        "    ax.plot(depths, evs_at_depth[:,i])\n",
        "\n",
        "ax.set_ylabel(\"Ground State Population\")\n",
        "ax.set_xlabel(\"Depth\")\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp93znodwlQi"
      },
      "source": [
        "Now we need to fit these to exponential decays, we can do this with the `lmfit` python package. The exponential decay has the following form:\n",
        "$$\n",
        "A\\alpha^L+B\n",
        "$$\n",
        "where $\\alpha$ is the error rate, $L$ denotes the number of cycles (depth) in the EPLG circuits, parameters $A$ and $B$ are the fitting parameters to capture the SPAM (state preparation and measurement) errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzUBLPmewlQj"
      },
      "outputs": [],
      "source": [
        "import lmfit\n",
        "model= lmfit.models.ExpressionModel(\n",
        "            expr=\"a * alpha ** x + b\",\n",
        "            name=\"rb_decay\")\n",
        "\n",
        "params_dict = {\n",
        "    'a': {'value': 1.0,\n",
        "            'min': -1.0,\n",
        "            'max': 1.0,\n",
        "            },\n",
        "    'b': {'value': 0.0,\n",
        "            'min': -1.0,\n",
        "            'max': 1.0,\n",
        "            },\n",
        "    'alpha': {'value': 0.9,\n",
        "              'min': 0.0,\n",
        "              'max': 1.0\n",
        "              },\n",
        "}\n",
        "p = model.make_params(**params_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25p-3JZRwlQj"
      },
      "outputs": [],
      "source": [
        "alphas = []\n",
        "for i in range(evs_at_depth.shape[-1]):\n",
        "    result = model.fit(evs_at_depth[:,i], p, x=depths)\n",
        "    alphas.append(result.params['alpha'].value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_k_z2BcwlQj"
      },
      "source": [
        "Now we can finally use the expressions in the EPLG paper to compute process fidelities.\n",
        "$\\alpha$ is related to the average gate error vis\n",
        "$$\n",
        "\\epsilon = \\frac{D-1}{D} (1-\\alpha)\n",
        "$$\n",
        "where $D$ denotes the the dimension of the Hilbert space, e.g., $D=4$ for two-qubit processes. The average gate fidelity is $F_g = 1-\\epsilon$.\n",
        "The process fidelity is related to the average gate fidelity via\n",
        "$$\n",
        "F_g=\\frac{DF_p+1}{D+1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr3m1_hlwlQj"
      },
      "outputs": [],
      "source": [
        "def cal_process_fid(alpha, D=4):\n",
        "    epsilon = (D-1) * (1 - alpha)/D\n",
        "    Fg = 1 - epsilon\n",
        "    Fp = ((D+1) * Fg -1)/D\n",
        "    return Fp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHTNu2UPwlQj"
      },
      "source": [
        "And with a little data-wrangling in `pandas` we can apply this to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXyC4MV1wlQj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "qubit_pairs = [item for pair in zip(LAYER_1_ANSWER, LAYER_2_ANSWER) for item in pair]\n",
        "pfs = [cal_process_fid(alpha) for alpha in alphas]\n",
        "df = pd.DataFrame(zip(qubit_pairs, alphas, pfs), columns=['qubit pair', 'alpha', 'process fidelity'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVoM83hwlQj"
      },
      "source": [
        "We now proceed to use the 2-qubit process fidelity `pfs` calculated above to compute the Layer Fidelity. For each value of the chain size, we take the largest Layer Fidelity from all the subchains measured. At the two ends of the chain, the 1-qubit process fidelity is approximated by the square root of the 2-qubit process fidelity. The data analysis code is adapted from the notebook [here](https://github.com/qiskit-community/qiskit-device-benchmarking/blob/main/notebooks/layer_fidelity.ipynb).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWS1euH5wlQj"
      },
      "outputs": [],
      "source": [
        "# Compute layer fidelity\n",
        "chain_lens = np.arange(2, len(pfs), 1)\n",
        "chain_fids = []\n",
        "for length in chain_lens:\n",
        "     w = length + 1  # window size\n",
        "     fid_w = max(\n",
        "          np.sqrt(pfs[s]) * np.prod(pfs[s + 1 : s + w - 1]) * np.sqrt(pfs[s + w - 1]) for s in range(len(pfs) - w + 1))\n",
        "     chain_fids.append(fid_w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRSsPP5swlQj"
      },
      "source": [
        "Now we can present the Layer Fidelity as a function of our chain length. This should decrease for larger chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVE24qY1wlQj"
      },
      "outputs": [],
      "source": [
        "# Plot LF by chain length\n",
        "plt.title(f\"Backend: {BACKEND.name}\")\n",
        "plt.plot(\n",
        "    chain_lens,\n",
        "    chain_fids,\n",
        "    marker=\"o\",\n",
        "    linestyle=\"-\",\n",
        ")\n",
        "plt.xlim(0, chain_lens[-1] * 1.05)\n",
        "plt.ylim(0.95 * min(chain_fids), 1)\n",
        "plt.ylabel(\"Layer Fidelity\")\n",
        "plt.xlabel(\"Chain Length\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIf-F-p5wlQj"
      },
      "source": [
        "Then, at long last, we can calculate the EPLG as a function of chain length. EPLG is defined as\n",
        "$$\n",
        "EPLG = 1 − LF^{1/n_{2q}}\n",
        "$$\n",
        "where $n_{2q}$ is the number of two-qubit gates in all the layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPqKW1MEwlQk"
      },
      "outputs": [],
      "source": [
        "# Plot EPLG by chain length\n",
        "num_2q_gates = [length - 1 for length in chain_lens]\n",
        "chain_eplgs = [\n",
        "    1 - (fid ** (1 / num_2q)) for num_2q, fid in zip(num_2q_gates, chain_fids)\n",
        "]\n",
        "plt.title(f\"Backend: {BACKEND.name}\")\n",
        "plt.plot(\n",
        "    chain_lens,\n",
        "    chain_eplgs,\n",
        "    marker=\"o\",\n",
        "    linestyle=\"-\",\n",
        ")\n",
        "plt.xlim(0, chain_lens[-1] * 1.05)\n",
        "plt.ylabel(\"Error per Layered Gates\")\n",
        "plt.xlabel(\"Chain Length\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr8yTdR6wlQk"
      },
      "source": [
        "This analysis is very useful in diagnosing which qubits and devices to use for utility-scale workloads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duZaEQI9wlQk",
        "outputId": "008f9989-abdc-4f05-859e-ddc0f1d0326a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style='width: 100%; background-color:#d5d9e0;padding-left: 10px; padding-bottom: 10px; padding-right: 10px; padding-top: 5px'><p>&copy; Copyright IBM 2017, 2024.</p><p>This code is licensed under the Apache License, Version 2.0. You may<br>obtain a copy of this license in the LICENSE.txt file in the root directory<br> of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.<p>Any modifications or derivative works of this code must retain this<br>copyright notice, and modified files need to carry a notice indicating<br>that they have been altered from the originals.</p></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datetime\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "def qiskit_copyright(line=\"\", cell=None):\n",
        "    \"\"\"IBM copyright\"\"\"\n",
        "    now = datetime.datetime.now()\n",
        "\n",
        "    html = \"<div style='width: 100%; background-color:#d5d9e0;\"\n",
        "    html += \"padding-left: 10px; padding-bottom: 10px; padding-right: 10px; padding-top: 5px'>\"\n",
        "    html += \"<p>&copy; Copyright IBM 2017, %s.</p>\" % now.year\n",
        "    html += \"<p>This code is licensed under the Apache License, Version 2.0. You may<br>\"\n",
        "    html += \"obtain a copy of this license in the LICENSE.txt file in the root directory<br> \"\n",
        "    html += \"of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\"\n",
        "\n",
        "    html += \"<p>Any modifications or derivative works of this code must retain this<br>\"\n",
        "    html += \"copyright notice, and modified files need to carry a notice indicating<br>\"\n",
        "    html += \"that they have been altered from the originals.</p>\"\n",
        "    html += \"</div>\"\n",
        "    return display(HTML(html))\n",
        "\n",
        "\n",
        "qiskit_copyright()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "runtime-latest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}